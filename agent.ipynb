{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from transformers import pipeline\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e649f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_RELATIVE_PATH = Path(\"AB_NYC_2019.csv\") / \"AB_NYC_2019.csv\"\n",
    "\n",
    "\n",
    "def load_local_airbnb_dataset() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Looks for the dataset at the specified local path, loads it, and cleans it\n",
    "    using Pandas/NumPy for statistical analysis and cleaning[cite: 68].\n",
    "    \"\"\"\n",
    "    csv_path = CSV_RELATIVE_PATH\n",
    "\n",
    "    if not csv_path.exists():\n",
    "        # Fallback for if the file is placed directly in the root (less likely based on image)\n",
    "        if Path(\"AB_NYC_2019.csv\").exists() and Path(\"AB_NYC_2019.csv\").is_file():\n",
    "             csv_path = Path(\"AB_NYC_2019.csv\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"[ERROR] Could not find the dataset at the expected local path: {CSV_RELATIVE_PATH}\\n\"\n",
    "                f\"Please ensure '{CSV_RELATIVE_PATH}' exists relative to the script.\"\n",
    "            )\n",
    "            sys.exit(1)\n",
    "\n",
    "    print(f\"[INFO] Loading dataset from {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Filtering columns to keep relevant data (as shown in the Dataset table)\n",
    "    cols = [\n",
    "        \"name\",\n",
    "        \"neighbourhood_group\", # Location [cite: 60]\n",
    "        \"neighbourhood\",       # Location [cite: 60]\n",
    "        \"room_type\",           # Listing Info [cite: 60]\n",
    "        \"price\",               # Listing Info [cite: 60]\n",
    "        \"minimum_nights\",      # Activity [cite: 60]\n",
    "        \"number_of_reviews\",   # Activity [cite: 60]\n",
    "        \"reviews_per_month\",   # Quality/Review frequency [cite: 60]\n",
    "    ]\n",
    "    df = df[cols].copy()\n",
    "\n",
    "    # Basic cleaning\n",
    "    df[\"name\"] = df[\"name\"].fillna(\"Unknown listing\")\n",
    "    df[\"reviews_per_month\"] = df[\"reviews_per_month\"].fillna(0.0)\n",
    "\n",
    "    # Drop rows with missing key fields\n",
    "    df = df.dropna(subset=[\"neighbourhood_group\", \"price\", \"room_type\"])\n",
    "\n",
    "    # Ensure price is numeric and positive\n",
    "    df = df[df[\"price\"] > 0]\n",
    "\n",
    "    print(f\"[INFO] Loaded {len(df)} listings after cleaning.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d32c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Search Module (TF-IDF) [cite: 33, 66]\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "class SearchModule:\n",
    "    \"\"\"Implements the Search Module using TF-IDF for keyword filtering[cite: 33].\"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "        print(\"[INFO] Building TF-IDF index over listing names...\")\n",
    "        self.X = self.vectorizer.fit_transform(self.df[\"name\"].astype(str))\n",
    "        print(\"[INFO] TF-IDF index built.\")\n",
    "\n",
    "    def search(self, query: str, k: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return top-k listings whose 'name' is most similar to the query.\n",
    "        \"\"\"\n",
    "        q_vec = self.vectorizer.transform([query])\n",
    "        sims = cosine_similarity(q_vec, self.X).flatten()\n",
    "        idx = sims.argsort()[::-1][:k]\n",
    "        return self.df.iloc[idx].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd732f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOROUGHS = [\"brooklyn\", \"manhattan\", \"queens\", \"bronx\", \"staten island\"]\n",
    "\n",
    "\n",
    "class PromptingModule:\n",
    "    \"\"\"\n",
    "    Implements the Prompting Module to parse user queries into structured \n",
    "    search conditions[cite: 34, 35].\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def parse_query(query: str):\n",
    "        \"\"\"\n",
    "        Convert natural language query into a simple action spec:\n",
    "            {\n",
    "              \"borough\": <str or None>,\n",
    "              \"task\": \"cheapest\" | \"average\" | \"search\"\n",
    "            }\n",
    "        \"\"\"\n",
    "        q = query.lower()\n",
    "        spec = {\"borough\": None, \"task\": None}\n",
    "\n",
    "        for b in BOROUGHS:\n",
    "            if b in q:\n",
    "                spec[\"borough\"] = b.title()\n",
    "                break\n",
    "\n",
    "        if \"cheapest\" in q or \"lowest price\" in q:\n",
    "            spec[\"task\"] = \"cheapest\"\n",
    "        elif \"average\" in q or \"avg\" in q or \"typical\" in q:\n",
    "            spec[\"task\"] = \"average\"\n",
    "        else:\n",
    "            spec[\"task\"] = \"search\"\n",
    "\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9b4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    \"\"\"\n",
    "    Uses the Hugging Face pipeline (FLAN-T5-small) to generate readable answers \n",
    "    and understand natural language[cite: 36, 67].\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.model_name = \"google/flan-t5-small\"\n",
    "        self.pipe = None\n",
    "\n",
    "        if pipeline is None:\n",
    "            print(\n",
    "                \"[WARN] transformers not installed. \"\n",
    "                \"Answers will be plain text without LLM refinement.\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"[INFO] Loading Hugging Face model: {self.model_name}...\")\n",
    "            self.pipe = pipeline(\n",
    "                \"text2text-generation\",\n",
    "                model=self.model_name\n",
    "            )\n",
    "            print(\"[INFO] Model loaded.\")\n",
    "\n",
    "    def generate(self, summary: str) -> str:\n",
    "        \"\"\"\n",
    "        If transformers is available, use FLAN-T5 to rewrite the summary.\n",
    "        Otherwise, just return the summary.\n",
    "        \"\"\"\n",
    "        if self.pipe is None:\n",
    "            return summary\n",
    "\n",
    "        prompt = (\n",
    "            \"You are an assistant summarizing Airbnb price information. \"\n",
    "            \"Rewrite the following summary into a concise, user-friendly sentence:\\n\\n\"\n",
    "            f\"{summary}\"\n",
    "        )\n",
    "        # LLM generation pipeline [cite: 48]\n",
    "        out = self.pipe(prompt, max_length=128, num_beams=4)[0][\"generated_text\"]\n",
    "        return out.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d5fd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirbnbAgent:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        # Components matching the workflow [cite: 32]\n",
    "        self.search_module = SearchModule(self.df)\n",
    "        self.prompting_module = PromptingModule()\n",
    "        self.language_model = LanguageModel()\n",
    "\n",
    "    def _filter_by_borough(self, borough: str | None) -> pd.DataFrame:\n",
    "        if borough is None:\n",
    "            return self.df\n",
    "        subset = self.df[self.df[\"neighbourhood_group\"] == borough]\n",
    "        if subset.empty:\n",
    "            return self.df\n",
    "        return subset\n",
    "\n",
    "    def _handle_cheapest(self, data: pd.DataFrame, borough: str | None) -> str:\n",
    "        # Response Formatter / Summarize insights (cheapest price) [cite: 37]\n",
    "        row = data.sort_values(\"price\").iloc[0]\n",
    "        b_label = borough if borough is not None else \"New York City\"\n",
    "        summary = (\n",
    "            f\"The cheapest listing in {b_label} is '{row['name']}' in \"\n",
    "            f\"{row['neighbourhood']} ({row['room_type']}) priced at \"\n",
    "            f\"${row['price']} per night, with {row['number_of_reviews']} reviews.\"\n",
    "        )\n",
    "        return self.language_model.generate(summary)\n",
    "\n",
    "    def _handle_average(self, data: pd.DataFrame, borough: str | None) -> str:\n",
    "        # Response Formatter / Summarize insights (average price) [cite: 37]\n",
    "        avg_price = round(data[\"price\"].mean(), 2)\n",
    "        n = len(data)\n",
    "        b_label = borough if borough is not None else \"New York City\"\n",
    "        summary = (\n",
    "            f\"The average nightly price in {b_label} is about \"\n",
    "            f\"${avg_price} based on {n} listings.\"\n",
    "        )\n",
    "        return self.language_model.generate(summary)\n",
    "\n",
    "    def _handle_search(self, query: str) -> str:\n",
    "        # Uses the Search Module [cite: 33]\n",
    "        results = self.search_module.search(query, k=5)\n",
    "        names = results[\"name\"].tolist()\n",
    "        prices = results[\"price\"].tolist()\n",
    "        neighbourhoods = results[\"neighbourhood\"].tolist()\n",
    "\n",
    "        items = [\n",
    "            f\"'{n}' in {nbhd} (${p}/night)\"\n",
    "            for n, nbhd, p in zip(names, neighbourhoods, prices)\n",
    "        ]\n",
    "        joined = \"; \".join(items)\n",
    "        # Response Formatter [cite: 37]\n",
    "        summary = (\n",
    "            f\"For your query '{query}', some relevant listings are: {joined}.\"\n",
    "        )\n",
    "        return self.language_model.generate(summary)\n",
    "\n",
    "    def answer(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Main entry point: processes a natural language query and returns an answer.\n",
    "        \"\"\"\n",
    "        # Uses the Prompting Module [cite: 34]\n",
    "        spec = self.prompting_module.parse_query(query)\n",
    "        borough = spec[\"borough\"]\n",
    "        task = spec[\"task\"]\n",
    "\n",
    "        data = self._filter_by_borough(borough)\n",
    "\n",
    "        if task == \"cheapest\":\n",
    "            return self._handle_cheapest(data, borough)\n",
    "        elif task == \"average\":\n",
    "            return self._handle_average(data, borough)\n",
    "        else:\n",
    "            return self._handle_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab218fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset from AB_NYC_2019.csv\\AB_NYC_2019.csv\n",
      "[INFO] Loaded 48884 listings after cleaning.\n",
      "[INFO] Building TF-IDF index over listing names...\n",
      "[INFO] TF-IDF index built.\n",
      "[INFO] Loading Hugging Face model: google/flan-t5-small...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7656782aa7945ed82abcfd8b21e2e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thais\\anaconda3\\envs\\airbnbchatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Thais\\.cache\\huggingface\\hub\\models--google--flan-t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40827519a0804ba9bb54d14c46df4388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d4da21e86544aaa28929dc8ad90963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913bfa4cff5a41299573e8e1502018db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846d5e5e43fc4d09ad281eb8f54eb12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43dc558cc4540c99905fda84ccc08f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model loaded.\n",
      "\n",
      "=== Airbnb Price Intelligence Agent Demo ===\n",
      "\n",
      "Q: What is the cheapest room in Brooklyn?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The cheapest listing in Brooklyn is 'Beautiful room in Bushwick' in Bushwick (Private room) priced at $10 per night, with 2 reviews.\n",
      "\n",
      "Q: What is the average price in Manhattan?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The average nightly price in Manhattan is about $196.88 based on 21660 listings.\n",
      "\n",
      "Q: Find a cheap private room near the park\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Cheap, furnished private room in Bensonhurst, Washington Heights, Washington Heights, Washington Heights, Washington Heights, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg, Williamsburg,\n",
      "\n",
      "Q: What is the average price in Queens?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The average nightly price in Queens is about $99.52 based on 5666 listings.\n",
      "\n",
      "Q: Show me the cheapest listing in New York City\n",
      "A: The cheapest listing in New York City is 'IT'S SIMPLY CONVENIENT!' in Jamaica (Entire home/apt) priced at $10 per night, with 43 reviews.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 1. Load dataset\n",
    "    df = load_local_airbnb_dataset()\n",
    "\n",
    "    # 2. Create agent\n",
    "    agent = AirbnbAgent(df)\n",
    "\n",
    "    # 3. Demo queries (Examples similar to the proposal's expected answers) [cite: 82]\n",
    "    queries = [\n",
    "        \"What is the cheapest room in Brooklyn?\", # Similar to \"Cheapest rooms in Boston\" [cite: 82]\n",
    "        \"What is the average price in Manhattan?\", # Similar to \"Average price in Boston\" [cite: 82]\n",
    "        \"Find a cheap private room near the park\",\n",
    "        \"What is the average price in Queens?\",\n",
    "        \"Show me the cheapest listing in New York City\",\n",
    "    ]\n",
    "\n",
    "    print(\"\\n=== Airbnb Price Intelligence Agent Demo ===\\n\")\n",
    "    for q in queries:\n",
    "        print(f\"Q: {q}\")\n",
    "        try:\n",
    "            ans = agent.answer(q)\n",
    "        except Exception as e:\n",
    "            ans = f\"[ERROR answering query: {e}]\"\n",
    "        print(f\"A: {ans}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnbchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
